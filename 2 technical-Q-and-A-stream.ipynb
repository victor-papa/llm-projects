{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0e5bd-b518-4cd0-a768-538e33d953fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull and specify the model - we try llama3.2:1b because llama3.2 runs very slow on the lappy\n",
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d868211f-7424-42cf-858e-7e2dcedb4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system prompt\n",
    "system_prompt = \"You are a computer science engineer with excellent programming knowlegde and communication skills. \\\n",
    "You receive a technical question and are capable of answering it in short and simple terms to someone with a less technical background.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user prompt: Question\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49e352a4-bec4-46cf-a1c7-560c0ebdf787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "def stream_answer_gpt(question):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model = MODEL_GPT,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "    # # print without markdown\n",
    "    # for chunk in stream:\n",
    "    #     print(chunk.choices[0].delta.content or '', end='')\n",
    "\n",
    "    # print with markdown\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "# Let's call ollama via the openAI library\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "def stream_answer_ollama(question, modelname = MODEL_LLAMA):\n",
    "    print(\"The answer below is generated by model: \" + modelname)\n",
    "    stream = ollama_via_openai.chat.completions.create(\n",
    "        model = modelname,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    # print with markdown\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "544a1bf4-3a92-416d-9d69-3222486d0690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Let's break down what this code does.\n",
       "\n",
       "1. **`{book.get(\"author\") for book in books if book.get(\"author\")}`**: This part of the code is a set comprehension. It creates a set (which is a collection of unique items) containing the authors of books. Here's how it works:\n",
       "   - It goes through each `book` in the `books` collection.\n",
       "   - For each `book`, it tries to get the value associated with the key `\"author\"`.\n",
       "   - If there's an author (i.e., `book.get(\"author\")` is not `None` or empty), it adds that author's name to the set.\n",
       "\n",
       "2. **`yield from ...`**: The `yield from` statement is used inside generators in Python. It allows you to yield all values from an iterable (like our set of authors) without having to loop through them explicitly. This means it will return each author one by one to whatever function or context is calling this generator.\n",
       "\n",
       "So, in summary, this code collects and yields unique authors from a list of books, skipping any books that don't have an author specified. Itâ€™s a concise way to get the authors while ensuring there are no duplicates."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN\n",
    "stream_answer_gpt(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75855048-6669-40cb-a73b-8089fed61d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer below is generated by model: deepseek-r1:1.5b\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Alright, I'm looking at this code: `yield from {book.get(\"author\") for book in books if book.get(\"author\")}`.\n",
       "\n",
       "First, I see that it's using Python. It runs three things:\n",
       "\n",
       "1. It starts a yield-withfrom loop to get the name of an object.\n",
       "2. Inside the loop, it creates a new generator expression by reading each item from \"books\". For each book, it gets its author if available, otherwise skips it.\n",
       "3. This generator is passed directly into the yield-withfrom loop.\n",
       "\n",
       "I'm not sure what exact object this code is looping over unless there's more context or defined variables elsewhere in the program where it refers to this loop. \n",
       "\n",
       "Looking at how Python evaluates loops, especially `yield from`, it iterates over each item from the iterable and executes all statements in order before returning control, stopping the iteration. So if there's a variable named \"books\" that contains books objects (like dictionaries or data structures), this code would collect the authors of these books into a generator expression and yield them one by one.\n",
       "\n",
       "But without more context about where \"books\" is defined, I can only guess. If \"books\" were a list containing objects with an \"author\" attribute, this code loops over each object, tries to get the author for each, collects the ones that exist (or perhaps all?), and yields their authors immediately one after another.\n",
       "\n",
       "I'm wondering if there's any potential issue here. One possible point of confusion is how Python handles dictionary literals in generator expressions. If \"book.get(\"author\")\" isn't valid syntax, it should raise an AttributeError, right? But usually, `get` on string keys like `\"author\"` expects something that returns a dictionary or raises a KeyError. So this line seems correct if the books are dictionaries with \"author\" as a key.\n",
       "\n",
       "Another thing is parallel execution and thread safety, but since each book in the generator expression contributes only one value (if any), I don't think concurrency issues apply here unless the code would yield early incorrectly if partial data were returned prematurely by generators or coroutines. But that's not directly relevant to this code because it uses `yield from` without considering such risks.\n",
       "\n",
       "In summary, the code is fetching the first author from each book in a list of books into a generator expression and yielding those authors one after another.\n",
       "</think>\n",
       "\n",
       "This code retrieves the \"author\" value for each book listed in the variable **books**. Each time it evaluates the loop body, it examines an item, checks if the key \"author\" is present (or is a dictionary returning such data), and returns that information immediately.\n",
       "\n",
       "In simpler terms:\n",
       "1. The loop starts without knowing where to begin.\n",
       "2. It loops through each book in the list **books**.\n",
       "3. For each book, it looks for an author field or creates a structure if it's not present.\n",
       "4. Only the authors are collected into a generator expression.\n",
       "5. This output is then returned one object at a time.\n",
       "\n",
       "So, the code retrieves a sequence of \"author\" fields from the list **books** and yields them sequentially."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN\n",
    "stream_answer_ollama(question, modelname = \"deepseek-r1:1.5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de917c30-8a09-41a7-8e40-517bca4e2a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
